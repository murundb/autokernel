{
  "task": "Write OpenCL kernel that implements the cuda kernel provided below __global__ void sampleMultinomialOnce(\n    int64_t* dest,\n    int64_t distributions,\n    int categories,\n    const scalar_t* sampled,\n    const scalar_t* dist,\n    int stride_dist, // dist->stride(0)\n    int stride_categories // dist->stride(1)\n) {\n  extern __shared__  unsigned char my_smem[];\n  __shared__ bool found;\n  __shared__ unsigned foundPos;\n\n  accscalar_t *smem = reinterpret_cast<accscalar_t *>(my_smem);\n\n  accscalar_t accZero = static_cast<accscalar_t>(0);\n  scalar_t zero = static_cast<scalar_t>(0);\n\n  for (int64_t curDist = blockIdx.x;\n       curDist < distributions; curDist += gridDim.x) {\n    // Each block handles one distribution\n    // First pass, find the total sum of the distribution\n    accscalar_t sum = accZero;\n    scalar_t val;\n    for (int cat = threadIdx.x; cat < categories; cat += blockDim.x) {\n      val = dist[curDist * stride_dist + cat * stride_categories];\n      CUDA_KERNEL_ASSERT(!at::_isnan(val));\n      CUDA_KERNEL_ASSERT(!_isinf(val));\n      CUDA_KERNEL_ASSERT(!(val < zero));\n      sum = sum + static_cast<accscalar_t>(val);\n    }\n\n    // threadIdx.x == 0 has the sum value from this\n    sum = cuda_utils::BlockReduceSum(sum, smem);\n\n    // Broadcast sum and sample value\n    if (threadIdx.x == 0) {\n      // Make sure the sum of our distribution didn't overflow\n      CUDA_KERNEL_ASSERT(!_isinf(val));\n      CUDA_KERNEL_ASSERT(sum > accZero);\n\n      foundPos = 0;\n      smem[0] = sum;\n      smem[1] = sampled[curDist];\n    }\n    __syncthreads();\n\n    sum = smem[0];\n    scalar_t sample = static_cast<scalar_t>(smem[1]);\n    __syncthreads();\n\n    if (sum == accZero) {\n      // Choose the first element\n      if (threadIdx.x == 0) {\n        dest[curDist] = 0;\n      }\n\n      continue;\n    }\n\n    int chunks = (categories + (int)blockDim.x - 1) / blockDim.x;\n    accscalar_t prevHighProb = accZero;\n    found = false;\n\n    for (int chunk = 0; chunk < chunks && !found; ++chunk) {\n      // All threads in bounds load a value\n      int cat = chunk * blockDim.x + threadIdx.x;\n\n      accscalar_t dist_val = cat < categories ?\n                             static_cast<accscalar_t>(dist[curDist * stride_dist + cat * stride_categories]) / sum :\n                             accZero;\n\n      smem[threadIdx.x] = dist_val;\n      __syncthreads();\n\n      // Perform an inclusive prefix sum of the shared memory contents\n      for (int offset = 1; offset < blockDim.x; offset *= 2) {\n        accscalar_t val = accZero;\n\n        if (threadIdx.x >= offset) {\n          val = smem[threadIdx.x - offset] + smem[threadIdx.x];\n        }\n\n        __syncthreads();\n        if (threadIdx.x >= offset) {\n          smem[threadIdx.x] = val;\n        }\n        __syncthreads();\n      }\n\n      // Each thread will check to see if the sample falls in its\n      // bucket\n      scalar_t curBucket =\n          static_cast<scalar_t>(smem[threadIdx.x] + prevHighProb);\n      scalar_t prevBucket = static_cast<scalar_t>(\n          threadIdx.x == 0 ? prevHighProb\n                          : smem[threadIdx.x - 1] + prevHighProb);\n      bool inBucket =\n          (cat < categories) &&\n          (!(sample >= curBucket) &&\n          (sample >= prevBucket) &&\n          (dist_val > zero));\n\n      if (inBucket) {\n        // We're done; we have the sample\n        // Torch indices are 1-based\n        atomicMax(&foundPos, cat);\n        found = true;\n      }\n\n      // Store the previous scan's high value for future use\n      prevHighProb = prevHighProb + smem[blockDim.x - 1];\n\n      __syncthreads();\n    }\n\n    if (threadIdx.x == 0) {\n      if (found) {\n          dest[curDist] = foundPos;\n      } else {\n        // This should address a rare bug where we don't select a valid index. This likely occurs when\n        // due to floating point arithmetic rounding errors, our cumulative sum does not add up to 1, but\n        // and our uniform sample is greater than this value. In this case we likely have unitialized memory\n        // in dest[curDist]. So basically we will loop through the distribution and pick the largest index\n        // where the distribution is non-zero. This is obviously terribly inefficient, but due to the\n        // rarity in which this occurs, this should not be an issue.\n        for (int cat = categories - 1; cat >= 0; --cat) {\n          if (dist[curDist * stride_dist + cat * stride_categories] > zero) {\n            dest[curDist] = cat;\n            break;\n          }\n        }\n      }\n    }\n  }\n}. The signature of the OpenCL kernel should match the signature of the cuda kernel.",
  "task_name": "sampleMultinomialOnce",
  "kernel_code": "def runner_setup():\n    import time\n    import numpy as np\n    import pyopencl as cl\n\n    # OpenCL code\n    opencl_code = \"\"\"__kernel void sampleMultinomialOnce(\n    __global long* dest,\n    const long distributions,\n    const int categories,\n    __global const float* sampled,\n    __global const float* dist,\n    const int stride_dist,\n    const int stride_categories,\n    __local float* smem)\n{\n    __local int foundPos;\n    __local int foundFlag;\n\n    float accZero = 0.0f;\n    float zero = 0.0f;\n    \n    const int lid = get_local_id(0);\n    const int local_size = get_local_size(0);\n    \n    for (long curDist = get_group_id(0);\n         curDist < distributions; curDist += get_num_groups(0)) {\n        // Each work-group handles one distribution\n        // First pass, find the total sum of the distribution\n        float sum = accZero;\n        float val;\n        for (int cat = lid; cat < categories; cat += local_size) {\n            val = dist[curDist * stride_dist + cat * stride_categories];\n            // Check for invalid values\n            if (isnan(val) || isinf(val) || val < zero) {\n                if (lid == 0) {\n                    dest[curDist] = -1; // Indicate error\n                }\n                return;\n            }\n            sum = sum + val;\n        }\n\n        // Perform reduction to get total sum\n        smem[lid] = sum;\n        barrier(CLK_LOCAL_MEM_FENCE);\n\n        for (uint stride = local_size / 2; stride > 0; stride >>= 1) {\n            if (lid < stride) {\n                smem[lid] += smem[lid + stride];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n\n        // Thread 0 now has the final sum\n        if (lid == 0) {\n            // Check for overflow or zero sum\n            if (isinf(smem[0]) || smem[0] <= accZero) {\n                // Choose first element\n                dest[curDist] = 0;\n                foundFlag = 1; // Skip remaining processing\n            } else {\n                foundPos = 0;\n                float total_sum = smem[0];\n                smem[0] = total_sum; // Store total sum\n                smem[1] = sampled[curDist]; // Store sample value\n                foundFlag = 0; // Continue processing\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n\n        if (foundFlag == 1) {\n            continue; // Skip to next distribution\n        }\n\n        sum = smem[0];\n        float sample = smem[1];\n        barrier(CLK_LOCAL_MEM_FENCE);\n\n        int chunks = (categories + local_size - 1) / local_size;\n        float prevHighProb = accZero;\n        foundFlag = 0; // Reset found flag\n\n        for (int chunk = 0; chunk < chunks && foundFlag == 0; ++chunk) {\n            // All threads in bounds load a value\n            int cat = chunk * local_size + lid;\n\n            float dist_val = cat < categories ?\n                          dist[curDist * stride_dist + cat * stride_categories] / sum :\n                          accZero;\n\n            smem[lid] = dist_val;\n            barrier(CLK_LOCAL_MEM_FENCE);\n\n            // Perform an inclusive prefix sum of the shared memory contents\n            for (int offset = 1; offset < local_size; offset *= 2) {\n                float val = accZero;\n\n                if (lid >= offset) {\n                    val = smem[lid - offset] + smem[lid];\n                }\n\n                barrier(CLK_LOCAL_MEM_FENCE);\n                if (lid >= offset) {\n                    smem[lid] = val;\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n\n            // Each thread will check to see if the sample falls in its bucket\n            float curBucket = smem[lid] + prevHighProb;\n            float prevBucket = lid == 0 ? prevHighProb : smem[lid - 1] + prevHighProb;\n            bool inBucket = (cat < categories) &&\n                          (!(sample >= curBucket) &&\n                          (sample >= prevBucket) &&\n                          (dist_val > zero));\n\n            if (inBucket) {\n                // We're done; we have the sample\n                atomic_max(&foundPos, cat);\n                // Fix atomic operation - use atomic_cmpxchg instead of atomic_store\n                atomic_cmpxchg(&foundFlag, 0, 1);\n            }\n\n            // Store the previous scan's high value for future use\n            prevHighProb = prevHighProb + smem[local_size - 1];\n\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n\n        if (lid == 0) {\n            if (foundFlag == 1) {\n                dest[curDist] = foundPos;\n            } else {\n                // This handles rare cases where no valid index is found\n                for (int cat = categories - 1; cat >= 0; --cat) {\n                    if (dist[curDist * stride_dist + cat * stride_categories] > zero) {\n                        dest[curDist] = cat;\n                        break;\n                    }\n                }\n            }\n        }\n    }\n}\"\"\"\n\n    # Setup parameters\n    distributions = 256  # Number of distributions\n    categories = 128     # Number of categories\n    stride_dist = categories  # Assuming row-major layout\n    stride_categories = 1    # Assuming row-major layout\n    \n    # Initialize data\n    np.random.seed(42)\n    \n    # Generate distributions (sum to 1)\n    dist_host = np.random.rand(distributions, categories).astype(np.float32)\n    dist_host = dist_host / dist_host.sum(axis=1)[:,np.newaxis]  # Normalize\n    \n    # Generate random samples between 0 and 1\n    sampled_host = np.random.rand(distributions).astype(np.float32)\n    \n    # Result buffer\n    dest_host = np.zeros(distributions, dtype=np.int64)\n    \n    # Initialize OpenCL\n    platforms = cl.get_platforms()\n    device = platforms[0].get_devices()[0]\n    context = cl.Context([device])\n    queue = cl.CommandQueue(context, properties=cl.command_queue_properties.PROFILING_ENABLE)\n    \n    # Create buffers\n    mf = cl.mem_flags\n    dest_buf = cl.Buffer(context, mf.WRITE_ONLY, size=dest_host.nbytes)\n    sampled_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=sampled_host)\n    dist_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=dist_host)\n    \n    # Build the program\n    program = cl.Program(context, opencl_code).build()\n    kernel = program.sampleMultinomialOnce\n    \n    # Determine work dimensions - NVIDIA GPUs work best with multiples of 32\n    local_size = 256  # Good size for NVIDIA GPUs\n    global_size = distributions * local_size // 4  # Ensure enough work-groups\n    \n    # Function to execute kernel and measure time\n    def run_kernel():\n        # Define the amount of local memory needed - include extra for foundPos and foundFlag\n        local_mem_size = local_size * np.dtype(np.float32).itemsize\n        \n        # Set kernel arguments\n        kernel.set_args(\n            dest_buf,\n            np.int64(distributions),\n            np.int32(categories),\n            sampled_buf,\n            dist_buf,\n            np.int32(stride_dist),\n            np.int32(stride_categories),\n            cl.LocalMemory(local_mem_size)\n        )\n        \n        # Execute kernel\n        event = cl.enqueue_nd_range_kernel(\n            queue, kernel, (global_size,), (local_size,)\n        )\n        event.wait()\n        \n        # Return execution time in milliseconds\n        return (event.profile.end - event.profile.start) * 1e-6\n    \n    # CPU reference implementation\n    def cpu_reference():\n        result = np.zeros(distributions, dtype=np.int64)\n        for i in range(distributions):\n            cdf = np.cumsum(dist_host[i])\n            sample = sampled_host[i]\n            # Find the bucket\n            for j in range(categories):\n                if sample < cdf[j]:\n                    result[i] = j\n                    break\n            else:  # If no bucket found\n                # Find last non-zero probability\n                for j in range(categories-1, -1, -1):\n                    if dist_host[i,j] > 0:\n                        result[i] = j\n                        break\n        return result\n    \n    # Function to verify results\n    def verify_results():\n        # Get CPU reference result\n        expected = cpu_reference()\n        \n        # Get GPU result\n        cl.enqueue_copy(queue, dest_host, dest_buf)\n        queue.finish()\n        \n        # Compare\n        max_diff = np.max(np.abs(dest_host - expected))\n        correct = np.array_equal(dest_host, expected)\n        return correct, f\"Max difference: {max_diff}, Correct: {correct}\"\n    \n    # Warmup run\n    run_kernel()\n    \n    # Benchmark\n    num_iterations = 10\n    times = []\n    \n    for i in range(num_iterations):\n        queue.finish()\n        start = time.time()\n        run_kernel()\n        queue.finish()\n        end = time.time()\n        elapsed = (end - start) * 1000  # Convert to ms\n        times.append(elapsed)\n        print(f\"Iteration {i+1}: {elapsed:.2f} ms\")\n    \n    # Verify results\n    is_correct, msg = verify_results()\n    \n    # Return timing results\n    return {\n        \"iterations\": num_iterations,\n        \"average_ms\": sum(times) / len(times),\n        \"min_ms\": min(times),\n        \"max_ms\": max(times),\n        \"all_times_ms\": times,\n        \"correct_result\": is_correct,\n        \"verification_feedback\": msg,\n        \"local_size\": local_size,\n        \"global_size\": global_size\n    }\n",
  "timing_info": {
    "iterations": 10,
    "average_ms": 0.04837512969970703,
    "min_ms": 0.046253204345703125,
    "max_ms": 0.05626678466796875,
    "all_times_ms": [
      0.05626678466796875,
      0.04863739013671875,
      0.04744529724121094,
      0.051021575927734375,
      0.04673004150390625,
      0.04673004150390625,
      0.046253204345703125,
      0.04673004150390625,
      0.04744529724121094,
      0.04649162292480469
    ],
    "correct_result": true,
    "verification_feedback": "Max difference: 0, Correct: True",
    "local_size": 256,
    "global_size": 16384
  }
}