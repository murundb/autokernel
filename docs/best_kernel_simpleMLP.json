{
  "task": "Write OpenCL kernel that implements a simple MLP: a linear layer (matrix-vector multiplication), followed by ReLU activation, followed by average pooling. The input is a vector of size 2048, the weight matrix is 2048x2048, and the output is a single float (the average of the ReLU outputs). The signature of the kernel should strictly be __kernel void simpleMLP(__global const float* restrict input, __global const float* restrict weights, __global float* restrict result, const int dim).",
  "kernel_code": "def runner_setup():\n    import time\n    import numpy as np\n    import pyopencl as cl\n\n    # Add the kernel code into a python string\n    opencl_code = \"\"\"\n    __kernel void simpleMLP(__global const float* restrict input,\n                          __global const float* restrict weights,\n                          __global float* restrict result,\n                          const int dim) {\n        // Use maximum local memory capacity\n        __local float input_cache[1024];  // NVIDIA can use larger local memory\n        __local float partial_sums[1024]; // For reduction\n        \n        const int gid = get_global_id(0);\n        const int lid = get_local_id(0);\n        const int wg_size = get_local_size(0);\n        const int wg_id = get_group_id(0);\n        const int num_groups = get_num_groups(0);\n        \n        // Initialize local sum\n        float my_sum = 0.0f;\n        \n        // Collaboratively load input vector into local memory\n        // Each work-item loads multiple elements\n        for (int i = lid; i < dim; i += wg_size) {\n            if (i < dim) {\n                input_cache[i % 1024] = input[i];\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        \n        // Calculate how many rows each work-item should process\n        const int rows_per_group = (dim + num_groups - 1) / num_groups;\n        const int start_row = wg_id * rows_per_group;\n        const int end_row = min(start_row + rows_per_group, dim);\n        \n        // Each thread processes multiple rows if needed within the assigned range\n        for (int row = start_row + lid; row < end_row; row += wg_size) {\n            // Compute dot product for this row\n            float dot_product = 0.0f;\n            \n            // Process the dot product in chunks to maintain cache efficiency\n            for (int c = 0; c < dim; c += 1024) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                // Collaboratively reload the next chunk of input if needed\n                if (c + 1024 < dim) {\n                    for (int i = lid; i < min(1024, dim - c); i += wg_size) {\n                        input_cache[i] = input[c + i];\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                // Process this chunk\n                const int chunk_end = min(c + 1024, dim);\n                for (int col = c; col < chunk_end; col++) {\n                    dot_product += weights[row * dim + col] * input_cache[col - c];\n                }\n            }\n            \n            // Apply ReLU activation\n            my_sum += max(0.0f, dot_product);\n        }\n        \n        // Store local result for reduction\n        partial_sums[lid] = my_sum;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        \n        // Parallel reduction within work-group (optimized for NVIDIA)\n        // Binary tree reduction is efficient on NVIDIA hardware\n        for (int stride = wg_size / 2; stride > 0; stride >>= 1) {\n            if (lid < stride) {\n                partial_sums[lid] += partial_sums[lid + stride];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        \n        // First thread in the work-group writes result to global memory\n        if (lid == 0) {\n            result[wg_id] = partial_sums[0];\n        }\n        \n        // Have work-item 0 calculate the final sum and average\n        if (gid == 0) {\n            barrier(CLK_GLOBAL_MEM_FENCE);\n            float final_sum = 0.0f;\n            for (int i = 0; i < num_groups; i++) {\n                final_sum += result[i];\n            }\n            result[0] = final_sum / dim;\n        }\n    }\n    \"\"\"\n\n    dim = 2048\n    num_iterations = 10\n\n    # Function to verify the results\n    def verification_fn():\n        # Calculate expected result on CPU\n        expected_result = 0.0\n        for i in range(dim):\n            dot_product = 0.0\n            for j in range(dim):\n                dot_product += weights_host[i * dim + j] * input_host[j]\n            # Apply ReLU\n            dot_product = max(0.0, dot_product)\n            expected_result += dot_product\n        expected_result /= dim\n        \n        # Get actual result\n        result_host = np.zeros(1, dtype=np.float32)\n        cl.enqueue_copy(queue, result_host, result_buf)\n        \n        # Compare\n        ok = np.isclose(result_host[0], expected_result, rtol=1e-3, atol=1e-3)\n        return ok, f\"Results {'match' if ok else 'do NOT match'}! Expected: {expected_result}, Got: {result_host[0]}\"\n\n    # Initialize data with random values\n    input_host = np.random.rand(dim).astype(np.float32)\n    weights_host = np.random.rand(dim * dim).astype(np.float32)\n    result_host = np.zeros(256, dtype=np.float32)  # Space for partial results\n    \n    # Create OpenCL context, queue, and buffers\n    platforms = cl.get_platforms()\n    if not platforms:\n        raise RuntimeError(\"No OpenCL platforms found.\")\n    platform = platforms[0]\n    devices = platform.get_devices()\n    if not devices:\n        raise RuntimeError(\"No OpenCL devices found.\")\n    device = devices[0]\n    print(f\"Using device: {device.name}\")\n    context = cl.Context([device])\n    queue = cl.CommandQueue(context)\n    \n    mf = cl.mem_flags\n    input_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=input_host)\n    weights_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=weights_host)\n    result_buf = cl.Buffer(context, mf.READ_WRITE, size=256 * np.dtype(np.float32).itemsize)\n    \n    # Compile the kernel\n    program = cl.Program(context, opencl_code).build()\n    kernel = program.simpleMLP\n    \n    # Set kernel arguments - maximize utilization of NVIDIA GPU\n    local_size = 256  # 256 is often optimal for NVIDIA GPUs despite supporting 1024\n    num_groups = min(32, (dim + local_size - 1) // local_size)  # Ensure good occupancy\n    global_size = num_groups * local_size\n    \n    execution_times = []\n    for i in range(num_iterations):\n        # Clear result buffer\n        cl.enqueue_fill_buffer(queue, result_buf, np.array([0], dtype=np.float32), 0, 256 * np.dtype(np.float32).itemsize)\n        queue.finish()\n        \n        # Launch kernel and time it\n        start_time = time.time()\n        kernel(queue, (global_size,), (local_size,), input_buf, weights_buf, result_buf, np.int32(dim))\n        queue.finish()\n        end_time = time.time()\n        \n        elapsed_time = (end_time - start_time) * 1000  # Convert to ms\n        execution_times.append(elapsed_time)\n        print(f\"Iteration {i+1}: {elapsed_time:.2f} ms\")\n    \n    # Calculate timing statistics\n    avg_time = sum(execution_times) / len(execution_times)\n    min_time = min(execution_times)\n    max_time = max(execution_times)\n    \n    # Verify result\n    is_correct, msg = verification_fn()\n    \n    timing_result = {\n        \"iterations\": num_iterations,\n        \"average_ms\": avg_time,\n        \"min_ms\": min_time,\n        \"max_ms\": max_time,\n        \"all_times_ms\": execution_times,\n        \"correct_result\": is_correct,\n        \"verification_feedback\": msg,\n        \"local_size\": local_size,\n        \"global_size\": global_size\n    }\n    \n    return timing_result",
  "timing_info": {
    "iterations": 10,
    "average_ms": 0.8172273635864258,
    "min_ms": 0.6175041198730469,
    "max_ms": 2.5777816772460938,
    "all_times_ms": [
      2.5777816772460938,
      0.6268024444580078,
      0.6198883056640625,
      0.6182193756103516,
      0.6198883056640625,
      0.6194114685058594,
      0.6177425384521484,
      0.6175041198730469,
      0.6208419799804688,
      0.6341934204101562
    ],
    "correct_result": "False",
    "verification_feedback": "Results do NOT match! Expected: 502.8447570800781, Got: 320.0769348144531",
    "local_size": 256,
    "global_size": 2048
  }
}