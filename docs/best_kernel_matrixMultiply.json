{
  "task": "Write OpenCL kernel that performs 4096x4096 matrix multiplication optimized for Qualcomm Adreno architecture. The signature of the kernel should be __kernel void matrixMultiply(__global const float* restrict A, __global const float* restrict B, __global float* restrict Result, const int matrix_dim).",
  "task_name": "matrixMultiply",
  "kernel_code": "def runner_setup():\n    import time\n    import numpy as np\n    import pyopencl as cl\n\n    # Define the OpenCL kernel\n    opencl_code = \"\"\"\n    __kernel void matrixMultiply(__global const float* restrict A, __global const float* restrict B, __global float* restrict Result, const int matrix_dim) {\n        // Define block size (tile size)\n        const int BLOCK_SIZE = 16;\n        \n        // Local memory for tiles - use fixed sizes for better memory allocation\n        __local float A_tile[BLOCK_SIZE][BLOCK_SIZE];\n        __local float B_tile[BLOCK_SIZE][BLOCK_SIZE];\n        \n        // Get block indices\n        const int block_row = get_group_id(0);\n        const int block_col = get_group_id(1);\n        \n        // Get local indices\n        const int local_row = get_local_id(0);\n        const int local_col = get_local_id(1);\n        \n        // Calculate global indices\n        const int global_row = BLOCK_SIZE * block_row + local_row;\n        const int global_col = BLOCK_SIZE * block_col + local_col;\n        \n        // Calculate row offset for each matrix to avoid redundant multiplications\n        const int A_row_offset = global_row * matrix_dim;\n        const int Result_row_offset = global_row * matrix_dim;\n        \n        // Use multiple accumulators for better instruction-level parallelism\n        float acc = 0.0f;\n        \n        // Calculate number of tile iterations needed\n        const int num_tiles = (matrix_dim + BLOCK_SIZE - 1) / BLOCK_SIZE;\n        \n        // Loop over all tiles needed for the multiplication\n        for (int t = 0; t < num_tiles; t++) {\n            const int tile_col = t * BLOCK_SIZE + local_col;\n            const int tile_row = t * BLOCK_SIZE + local_row;\n            \n            // Load A tile - optimize bounds checking\n            if (global_row < matrix_dim && tile_col < matrix_dim) {\n                A_tile[local_row][local_col] = A[A_row_offset + tile_col];\n            } else {\n                A_tile[local_row][local_col] = 0.0f;\n            }\n            \n            // Load B tile - optimize bounds checking\n            if (tile_row < matrix_dim && global_col < matrix_dim) {\n                B_tile[local_row][local_col] = B[tile_row * matrix_dim + global_col];\n            } else {\n                B_tile[local_row][local_col] = 0.0f;\n            }\n            \n            // Wait for all work-items to complete loading\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            // Compute partial dot product with fully unrolled loop for better performance\n            // This works better on Adreno GPUs than partial unrolling\n            #pragma unroll\n            for (int k = 0; k < BLOCK_SIZE; k++) {\n                acc += A_tile[local_row][k] * B_tile[k][local_col];\n            }\n            \n            // Ensure all computations are done before loading new tiles\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        \n        // Write the result to global memory\n        if (global_row < matrix_dim && global_col < matrix_dim) {\n            Result[Result_row_offset + global_col] = acc;\n        }\n    }\n    \"\"\"\n\n    # Matrix dimensions\n    matrix_dim = 4096\n    \n    # Function to verify results\n    def verification_fn():\n        # Copy result back to host\n        result_host = np.empty((matrix_dim, matrix_dim), dtype=np.float32)\n        cl.enqueue_copy(queue, result_host, result_buf)\n        \n        # Compute expected result on CPU\n        expected = np.matmul(A_host, B_host)\n        \n        # Check if results match\n        is_correct = np.allclose(result_host, expected, rtol=1e-4, atol=1e-4)\n        message = \"Results match!\" if is_correct else \"Results do NOT match!\"\n        return is_correct, message\n\n    # Initialize matrices with random data\n    A_host = np.random.rand(matrix_dim, matrix_dim).astype(np.float32)\n    B_host = np.random.rand(matrix_dim, matrix_dim).astype(np.float32)\n    \n    # Set up OpenCL\n    platforms = cl.get_platforms()\n    if not platforms:\n        raise RuntimeError(\"No OpenCL platforms found.\")\n    \n    platform = platforms[0]\n    devices = platform.get_devices()\n    device = devices[0]\n    print(f\"Using OpenCL device: {device.name}\")\n    \n    ctx = cl.Context([device])\n    queue = cl.CommandQueue(ctx)\n    \n    # Create buffers\n    mf = cl.mem_flags\n    A_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=A_host)\n    B_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=B_host)\n    result_buf = cl.Buffer(ctx, mf.WRITE_ONLY, size=matrix_dim * matrix_dim * np.dtype(np.float32).itemsize)\n    \n    # Build the program\n    program = cl.Program(ctx, opencl_code).build()\n    matmul_kernel = program.matrixMultiply\n    \n    # Set kernel arguments\n    args = (A_buf, B_buf, result_buf, np.int32(matrix_dim))\n    \n    # Set work dimensions\n    block_size = 16  # Same as BLOCK_SIZE in the kernel\n    grid_size = (matrix_dim + block_size - 1) // block_size\n    global_size = (grid_size * block_size, grid_size * block_size)\n    local_size = (block_size, block_size)\n    \n    # Number of iterations for benchmarking\n    num_iterations = 5\n    execution_times = []\n    \n    for i in range(num_iterations):\n        # Run the kernel and measure execution time\n        queue.finish()\n        start_time = time.time()\n        \n        matmul_kernel(queue, global_size, local_size, *args)\n        \n        queue.finish()\n        end_time = time.time()\n        \n        elapsed_time = (end_time - start_time) * 1000  # Convert to milliseconds\n        execution_times.append(elapsed_time)\n        print(f\"Iteration {i+1}: {elapsed_time:.2f} ms\")\n    \n    # Calculate statistics\n    avg_time = sum(execution_times) / len(execution_times)\n    min_time = min(execution_times)\n    max_time = max(execution_times)\n    \n    # Verify the result\n    is_correct, msg = verification_fn()\n    \n    # Return timing results\n    timing_result = {\n        \"iterations\": num_iterations,\n        \"average_ms\": avg_time,\n        \"min_ms\": min_time,\n        \"max_ms\": max_time,\n        \"all_times_ms\": execution_times,\n        \"correct_result\": is_correct,\n        \"verification_feedback\": msg,\n        \"block_size\": block_size,\n        \"grid_size\": grid_size\n    }\n    \n    return timing_result\n",
  "timing_info": {
    "iterations": 5,
    "average_ms": 151.1603832244873,
    "min_ms": 142.64869689941406,
    "max_ms": 176.09763145446777,
    "all_times_ms": [
      176.09763145446777,
      151.72696113586426,
      142.67683029174805,
      142.64869689941406,
      142.65179634094238
    ],
    "correct_result": true,
    "verification_feedback": "Results match!",
    "block_size": 16,
    "grid_size": 256
  }
}