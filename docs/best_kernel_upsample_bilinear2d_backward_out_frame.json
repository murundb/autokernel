{
  "task": "Write OpenCL kernel that implements the cuda kernel provided below __global__ void upsample_bilinear2d_backward_out_frame(\n    const size_t nc,\n    const int height1,\n    const int width1,\n    const int height2,\n    const int width2,\n    const accscalar_t rheight,\n    const accscalar_t rwidth,\n    const bool align_corners,\n    scalar_t* __restrict__ idata,\n    const scalar_t* __restrict__ odata) {\n  const size_t o_numel = nc * width2 * height2;\n  const size_t i_numel = nc * width1 * height1;\n  for (size_t index = blockDim.x * blockIdx.x + threadIdx.x; index < o_numel;\n       index += blockDim.x * gridDim.x) {\n    size_t index_temp = index;\n    const int w2 = index_temp % width2; // 0:width2-1\n    index_temp /= width2;\n    const int h2 = index_temp % height2; // 0:height2-1\n    const size_t nc = index_temp / height2;\n    //\n    const accscalar_t h1r = area_pixel_compute_source_index<accscalar_t>(\n        rheight, h2, align_corners, /*cubic=*/false);\n    const int h1 = h1r;\n    const int h1p = (h1 < height1 - 1) ? 1 : 0;\n    const accscalar_t h1lambda = h1r - h1;\n    const accscalar_t h0lambda = static_cast<accscalar_t>(1) - h1lambda;\n    //\n    const accscalar_t w1r = area_pixel_compute_source_index<accscalar_t>(\n        rwidth, w2, align_corners, /*cubic=*/false);\n    const int w1 = w1r;\n    const int w1p = (w1 < width1 - 1) ? 1 : 0;\n    const accscalar_t w1lambda = w1r - w1;\n    const accscalar_t w0lambda = static_cast<accscalar_t>(1) - w1lambda;\n    //\n    const scalar_t d2val = odata[index];\n    fastAtomicAdd(\n        idata,\n        idx(nc, height1, width1, h1, w1),\n        i_numel,\n        static_cast<scalar_t>(h0lambda * w0lambda * d2val),\n        true);\n    fastAtomicAdd(\n        idata,\n        idx(nc, height1, width1, h1, w1 + w1p),\n        i_numel,\n        static_cast<scalar_t>(h0lambda * w1lambda * d2val),\n        true);\n    fastAtomicAdd(\n        idata,\n        idx(nc, height1, width1, h1 + h1p, w1),\n        i_numel,\n        static_cast<scalar_t>(h1lambda * w0lambda * d2val),\n        true);\n    fastAtomicAdd(\n        idata,\n        idx(nc, height1, width1, h1 + h1p, w1 + w1p),\n        i_numel,\n        static_cast<scalar_t>(h1lambda * w1lambda * d2val),\n        true);\n  }\n}. The signature of the OpenCL kernel should match the signature of the cuda kernel.",
  "task_name": "upsample_bilinear2d_backward_out_frame",
  "kernel_code": "def runner_setup():\n    import time\n    import numpy as np\n    import pyopencl as cl\n\n    # Define OpenCL kernel code\n    opencl_code = \"\"\"\n    // Helper function to compute the source index for pixel mapping\n    inline float area_pixel_compute_source_index(\n        float scale, int dst_index, int align_corners, int cubic) {\n      if (align_corners) {\n        return dst_index * scale;\n      } else {\n        float src_idx = scale * (dst_index + 0.5f) - 0.5f;\n        return src_idx < 0 ? 0 : src_idx;\n      }\n    }\n\n    // Helper function to compute linear index from multidimensional coordinates\n    inline ulong idx(ulong nc, int height, int width, int h, int w) {\n      return (nc * height + h) * width + w;\n    }\n\n    // Atomic add function for float values\n    inline void atomic_add_float(volatile __global float *addr, float val) {\n      union {\n        unsigned int u32;\n        float f32;\n      } next, expected, current;\n      current.f32 = *addr;\n      do {\n        expected.f32 = current.f32;\n        next.f32 = expected.f32 + val;\n        current.u32 = atomic_cmpxchg((volatile __global unsigned int *)addr,\n                                    expected.u32, next.u32);\n      } while (current.u32 != expected.u32);\n    }\n\n    // Fast atomic add that checks bounds\n    inline void fastAtomicAdd(__global float *addr, ulong index, ulong numel,\n                            float val, int check_bounds) {\n      if (!check_bounds || index < numel) {\n        atomic_add_float(&addr[index], val);\n      }\n    }\n\n    __kernel void upsample_bilinear2d_backward_out_frame(\n        const ulong nc,\n        const int height1,\n        const int width1,\n        const int height2,\n        const int width2,\n        const float rheight,\n        const float rwidth,\n        const int align_corners,\n        __global float* restrict idata,\n        const __global float* restrict odata) {\n      \n      const ulong o_numel = nc * width2 * height2;\n      const ulong i_numel = nc * width1 * height1;\n      \n      // Use 1D grid of work-items\n      const ulong index = get_global_id(0);\n      if (index >= o_numel) return;\n      \n      // Calculate 3D coordinates from linear index\n      ulong index_temp = index;\n      const int w2 = index_temp % width2; // 0:width2-1\n      index_temp /= width2;\n      const int h2 = index_temp % height2; // 0:height2-1\n      const ulong nc_idx = index_temp / height2;\n      \n      // Compute source indices and weights\n      const float h1r = area_pixel_compute_source_index(\n          rheight, h2, align_corners, 0);\n      const int h1 = (int)h1r;\n      const int h1p = (h1 < height1 - 1) ? 1 : 0;\n      const float h1lambda = h1r - h1;\n      const float h0lambda = 1.0f - h1lambda;\n      \n      const float w1r = area_pixel_compute_source_index(\n          rwidth, w2, align_corners, 0);\n      const int w1 = (int)w1r;\n      const int w1p = (w1 < width1 - 1) ? 1 : 0;\n      const float w1lambda = w1r - w1;\n      const float w0lambda = 1.0f - w1lambda;\n      \n      // Get the output value - only read once from global memory\n      const float d2val = odata[index];\n      \n      // Compute weighted contributions\n      const float grad_h0w0 = h0lambda * w0lambda * d2val;\n      const float grad_h0w1 = h0lambda * w1lambda * d2val;\n      const float grad_h1w0 = h1lambda * w0lambda * d2val;\n      const float grad_h1w1 = h1lambda * w1lambda * d2val;\n      \n      // Compute indices for the four affected input pixels\n      const ulong idx_h0w0 = idx(nc_idx, height1, width1, h1, w1);\n      const ulong idx_h0w1 = idx(nc_idx, height1, width1, h1, w1 + w1p);\n      const ulong idx_h1w0 = idx(nc_idx, height1, width1, h1 + h1p, w1);\n      const ulong idx_h1w1 = idx(nc_idx, height1, width1, h1 + h1p, w1 + w1p);\n      \n      // Perform atomic additions\n      fastAtomicAdd(idata, idx_h0w0, i_numel, grad_h0w0, 1);\n      fastAtomicAdd(idata, idx_h0w1, i_numel, grad_h0w1, 1);\n      fastAtomicAdd(idata, idx_h1w0, i_numel, grad_h1w0, 1);\n      fastAtomicAdd(idata, idx_h1w1, i_numel, grad_h1w1, 1);\n    }\n    \"\"\"\n\n    # Test parameters\n    batch_size = 8\n    channels = 16\n    height1 = 32\n    width1 = 32\n    height2 = 64\n    width2 = 64\n    align_corners = False\n    \n    # Calculate scales\n    if align_corners:\n        rheight = float(height1 - 1) / (height2 - 1) if height2 > 1 else 0.0\n        rwidth = float(width1 - 1) / (width2 - 1) if width2 > 1 else 0.0\n    else:\n        rheight = float(height1) / height2\n        rwidth = float(width1) / width2\n    \n    nc = batch_size * channels\n    o_numel = nc * height2 * width2\n    i_numel = nc * height1 * width1\n    \n    # Initialize data\n    np.random.seed(42)\n    idata_host = np.zeros((batch_size, channels, height1, width1), dtype=np.float32)\n    odata_host = np.random.rand(batch_size, channels, height2, width2).astype(np.float32)\n    \n    # Reshape to match kernel expectations\n    idata_flat = idata_host.reshape(-1)\n    odata_flat = odata_host.reshape(-1)\n    \n    # Set up OpenCL\n    platforms = cl.get_platforms()\n    if not platforms:\n        raise RuntimeError(\"No OpenCL platforms found.\")\n    \n    # Choose platform and device\n    platform = platforms[0]\n    device = platform.get_devices()[0]\n    print(f\"Using OpenCL device: {device.name}\")\n    \n    # Create context and queue\n    ctx = cl.Context([device])\n    queue = cl.CommandQueue(ctx)\n    \n    # Create buffers\n    mf = cl.mem_flags\n    idata_buf = cl.Buffer(ctx, mf.READ_WRITE | mf.COPY_HOST_PTR, hostbuf=idata_flat)\n    odata_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=odata_flat)\n    \n    # Build program\n    program = cl.Program(ctx, opencl_code).build()\n    kernel = program.upsample_bilinear2d_backward_out_frame\n    \n    # Verification function\n    def area_pixel_compute_source_index_numpy(scale, dst_index, align_corners):\n        if align_corners:\n            return dst_index * scale\n        else:\n            src_idx = scale * (dst_index + 0.5) - 0.5\n            return max(0, src_idx)\n            \n    def verification_fn():\n        # Get the OpenCL result\n        cl_result = np.zeros_like(idata_flat)\n        cl.enqueue_copy(queue, cl_result, idata_buf)\n        \n        # Compute the reference result using NumPy/CPU\n        ref_result = np.zeros_like(idata_flat)\n        \n        # Reshape to match dimensions\n        ref_result = ref_result.reshape(batch_size, channels, height1, width1)\n        odata_reshaped = odata_host.reshape(batch_size, channels, height2, width2)\n        \n        # Reference implementation\n        for b in range(batch_size):\n            for c in range(channels):\n                for h2 in range(height2):\n                    for w2 in range(width2):\n                        # Compute source indices\n                        h1r = area_pixel_compute_source_index_numpy(rheight, h2, align_corners)\n                        h1 = int(h1r)\n                        h1p = 1 if h1 < height1 - 1 else 0\n                        h1lambda = h1r - h1\n                        h0lambda = 1.0 - h1lambda\n                        \n                        w1r = area_pixel_compute_source_index_numpy(rwidth, w2, align_corners)\n                        w1 = int(w1r)\n                        w1p = 1 if w1 < width1 - 1 else 0\n                        w1lambda = w1r - w1\n                        w0lambda = 1.0 - w1lambda\n                        \n                        # Get output value\n                        d2val = odata_reshaped[b, c, h2, w2]\n                        \n                        # Update input tensor\n                        ref_result[b, c, h1, w1] += h0lambda * w0lambda * d2val\n                        ref_result[b, c, h1, w1 + w1p] += h0lambda * w1lambda * d2val\n                        ref_result[b, c, h1 + h1p, w1] += h1lambda * w0lambda * d2val\n                        ref_result[b, c, h1 + h1p, w1 + w1p] += h1lambda * w1lambda * d2val\n        \n        # Flatten reference result\n        ref_result = ref_result.reshape(-1)\n        \n        # Compare results\n        max_diff = np.abs(cl_result - ref_result).max()\n        is_correct = max_diff < 1e-5\n        msg = f\"Results match! Max diff: {max_diff}\" if is_correct else f\"Results do NOT match! Max diff: {max_diff}\"\n        \n        return is_correct, msg\n    \n    # Run the kernel\n    num_iterations = 10\n    execution_times = []\n    \n    # Determine work group size\n    max_work_group_size = device.max_work_group_size\n    work_group_size = min(256, max_work_group_size)  # Use 256 or less if device limits it\n    \n    # Determine global work size (must be multiple of work group size)\n    global_work_size = ((o_numel + work_group_size - 1) // work_group_size) * work_group_size\n    \n    for i in range(num_iterations):\n        # Reset input buffer to zeros before each run\n        cl.enqueue_copy(queue, idata_buf, np.zeros_like(idata_flat))\n        \n        queue.finish()\n        start_time = time.time()\n        \n        # Launch kernel\n        kernel(queue, (global_work_size,), (work_group_size,),\n              np.uint64(nc), np.int32(height1), np.int32(width1),\n              np.int32(height2), np.int32(width2),\n              np.float32(rheight), np.float32(rwidth),\n              np.int32(align_corners), idata_buf, odata_buf)\n        \n        queue.finish()\n        end_time = time.time()\n        elapsed_time = (end_time - start_time) * 1000  # Convert to ms\n        \n        execution_times.append(elapsed_time)\n        print(f\"Iteration {i+1}: {elapsed_time:.2f} ms\")\n    \n    # Compute statistics\n    avg_time = sum(execution_times) / len(execution_times)\n    min_time = min(execution_times)\n    max_time = max(execution_times)\n    \n    # Verify results\n    is_correct, msg = verification_fn()\n    \n    timing_result = {\n        \"iterations\": num_iterations,\n        \"average_ms\": avg_time,\n        \"min_ms\": min_time,\n        \"max_ms\": max_time,\n        \"all_times_ms\": execution_times,\n        \"correct_result\": is_correct,\n        \"verification_feedback\": msg,\n        \"work_group_size\": work_group_size,\n        \"global_work_size\": global_work_size\n    }\n    \n    return timing_result",
  "timing_info": {
    "iterations": 10,
    "average_ms": 0.18222332000732422,
    "min_ms": 0.14472007751464844,
    "max_ms": 0.49614906311035156,
    "all_times_ms": [
      0.49614906311035156,
      0.15664100646972656,
      0.1480579376220703,
      0.14591217041015625,
      0.14591217041015625,
      0.14710426330566406,
      0.14710426330566406,
      0.14472007751464844,
      0.14519691467285156,
      0.14543533325195312
    ],
    "correct_result": "True",
    "verification_feedback": "Results match! Max diff: 9.5367431640625e-07",
    "work_group_size": 256,
    "global_work_size": 524288
  }
}