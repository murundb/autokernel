{
  "task": "Write OpenCL kernel that implements the cuda kernel provided below __global__ void unique_bool_write_inverse_indices(\n    const int numel,\n    const int *num_true_p,\n    const bool *self,\n    int64_t *inverse_indices_out) {\n  constexpr int false_idx = 0;\n  const int num_true = *num_true_p;\n  const int num_false = numel - num_true;\n  const int true_idx = num_false > 0;\n\n  CUDA_KERNEL_LOOP(i, numel) {\n    const auto value = c10::load(&self[i]);\n    inverse_indices_out[i] = value ? true_idx : false_idx;\n  }\n}. The signature of the OpenCL kernel should match the signature of the cuda kernel.",
  "task_name": "unique_bool_write_inverse_indices",
  "kernel_code": "def runner_setup():\n    import time\n    import numpy as np\n    import pyopencl as cl\n\n    # Add the kernel code\n    opencl_code = \"\"\"\n    __kernel void unique_bool_write_inverse_indices(\n        const int numel,\n        __global const int * restrict num_true_p,\n        __global const uchar * restrict self,\n        __global long * restrict inverse_indices_out) {\n        \n        // Read num_true value from global memory only once\n        const int false_idx = 0;\n        const int num_true = *num_true_p;\n        const int num_false = numel - num_true;\n        const int true_idx = (num_false > 0) ? 1 : 0;\n        \n        // Process multiple elements per thread for better utilization\n        const int gid = get_global_id(0);\n        const int stride = get_global_size(0);\n        \n        for (int i = gid; i < numel; i += stride) {\n            const uchar value = self[i];\n            inverse_indices_out[i] = value ? true_idx : false_idx;\n        }\n    }\n    \"\"\"\n\n    # Initialize data with random boolean values\n    numel = 10000000  # 10M elements to ensure we have a significant workload\n    self_host = np.random.choice([True, False], size=numel).astype(np.uint8)\n    num_true = np.sum(self_host).astype(np.int32)\n    num_true_host = np.array([num_true], dtype=np.int32)\n    inverse_indices_host = np.zeros(numel, dtype=np.int64)\n    \n    # Function to verify the results\n    def verification_fn():\n        result_host = np.empty(numel, dtype=np.int64)\n        cl.enqueue_copy(queue, result_host, inverse_indices_buf)\n        \n        num_false = numel - num_true\n        true_idx = 1 if num_false > 0 else 0\n        false_idx = 0\n        \n        expected = np.where(self_host, true_idx, false_idx)\n        ok = np.array_equal(result_host, expected)\n        return ok, \"Results match!\" if ok else \"Results do NOT match!\"\n\n    # Create OpenCL context, queue, and buffers\n    platforms = cl.get_platforms()\n    if not platforms:\n        raise RuntimeError(\"No OpenCL platforms found.\")\n    \n    platform = platforms[0]\n    devices = platform.get_devices()\n    if not devices:\n        raise RuntimeError(\"No OpenCL devices found on the selected platform.\")\n    \n    device = devices[0]\n    print(f\"Using OpenCL device: {device.name}\")\n    \n    ctx = cl.Context([device])\n    queue = cl.CommandQueue(ctx)\n    \n    mf = cl.mem_flags\n    num_true_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=num_true_host)\n    self_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=self_host)\n    inverse_indices_buf = cl.Buffer(ctx, mf.WRITE_ONLY, size=numel * np.dtype(np.int64).itemsize)\n    \n    # Build the kernel\n    program = cl.Program(ctx, opencl_code).build()\n    kernel = program.unique_bool_write_inverse_indices\n    \n    # Set work sizes - adjust based on device capabilities\n    local_size = 256  # Work group size\n    global_size = ((numel + local_size - 1) // local_size) * local_size  # Round up to multiple of local_size\n    \n    # Execute the kernel multiple times and measure performance\n    num_iterations = 10\n    execution_times = []\n    \n    for i in range(num_iterations):\n        args = (np.int32(numel), num_true_buf, self_buf, inverse_indices_buf)\n        queue.finish()\n        start_time = time.time()\n        kernel(queue, (global_size,), (local_size,), *args)\n        queue.finish()\n        end_time = time.time()\n        elapsed_time = (end_time - start_time) * 1000  # Convert to ms\n        execution_times.append(elapsed_time)\n        print(f\"Iteration {i+1}: {elapsed_time:.2f} ms\")\n    \n    # Calculate statistics\n    avg_time = sum(execution_times) / len(execution_times)\n    min_time = min(execution_times)\n    max_time = max(execution_times)\n    \n    # Verify results\n    is_correct, msg = verification_fn()\n    \n    # Return performance metrics and verification result\n    timing_result = {\n        \"iterations\": num_iterations,\n        \"average_ms\": avg_time,\n        \"min_ms\": min_time,\n        \"max_ms\": max_time,\n        \"all_times_ms\": execution_times,\n        \"correct_result\": is_correct,\n        \"verification_feedback\": msg,\n        \"local_size\": local_size,\n        \"global_size\": global_size\n    }\n    return timing_result",
  "timing_info": {
    "iterations": 10,
    "average_ms": 0.3213644027709961,
    "min_ms": 0.2129077911376953,
    "max_ms": 1.2769699096679688,
    "all_times_ms": [
      1.2769699096679688,
      0.22792816162109375,
      0.21409988403320312,
      0.21409988403320312,
      0.21386146545410156,
      0.21314620971679688,
      0.213623046875,
      0.21338462829589844,
      0.213623046875,
      0.2129077911376953
    ],
    "correct_result": true,
    "verification_feedback": "Results match!",
    "local_size": 256,
    "global_size": 10000128
  }
}